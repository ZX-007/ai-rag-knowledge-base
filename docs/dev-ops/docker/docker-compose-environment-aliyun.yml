# docker compose -f docker-compose-environment-aliyun.yml up -d
services:
  ollama:
    image: registry.cn-hangzhou.aliyuncs.com/xfg-studio/ollama:0.5.10
    container_name: ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - /opt/llm/ollama/models:/root/.ollama/models
    entrypoint:
      - /bin/sh
      - -c
      - |
        /bin/ollama serve & 
        echo "Waiting 5 seconds for Ollama server startup..."
        sleep 5
        /bin/ollama run deepseek-r1:1.5b
        wait
    networks:
      - network
    # 对话模型：ollama run deepseek-r1:1.5b
    # 嵌入模型：ollama run nomic-embed-text

  redis:
    image: registry.cn-hangzhou.aliyuncs.com/xfg-studio/redis:6.2
    container_name: redis
    restart: always
    privileged: true
    ports:
      - "6379:6379"
    volumes:
      - ./redis/data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      - network
    healthcheck:
      test: [ "CMD", "redis-cli", "-a", "root", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 3

  pgvector:
    image: registry.cn-hangzhou.aliyuncs.com/xfg-studio/pgvector:v0.5.0
    container_name: pgvector
    restart: always
    environment:
      - POSTGRES_USER=root
      - POSTGRES_PASSWORD=root
      - PGPASSWORD=root
      - POSTGRES_DB=ai-rag-knowledge-base
    volumes:
      - ./pgvector/data:/var/lib/postgresql/data
      - ./pgvector/sql/init.sql:/docker-entrypoint-initdb.d/init.sql
    logging:
      options:
        max-size: 10m
        max-file: "3"
    ports:
      - '5432:5432'
    healthcheck:
      test: "pg_isready -U root -d ai-rag-knowledge-base"
      interval: 5s
      timeout: 30s
      retries: 10
    networks:
      - network

networks:
  network:
    driver: bridge